"""
í†µí•© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œìŠ¤í…œ
ëª¨ë“  CSV íŒŒì¼ì„ ë¶„ì„í•˜ê³  í‘œì¤€í™”ëœ í˜•íƒœë¡œ ë³€í™˜
"""

import pandas as pd
import numpy as np
import os
import re
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import logging
from pathlib import Path

@dataclass
class DatasetInfo:
    """ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤"""
    filename: str
    shape: Tuple[int, int]
    columns: List[str]
    data_types: Dict[str, str]
    has_year_columns: bool
    year_columns: List[str]
    numeric_columns: List[str]
    categorical_columns: List[str]
    missing_values: Dict[str, int]
    description: str

class DataPreprocessor:
    """ëª¨ë“  CSV í†µí•© ë° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_folder: str):
        """
        ë°ì´í„° ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            data_folder: ë°ì´í„° í´ë” ê²½ë¡œ
        """
        self.data_folder = Path(data_folder)
        self.datasets: Dict[str, pd.DataFrame] = {}
        self.dataset_info: Dict[str, DatasetInfo] = {}
        self.unified_data: Optional[pd.DataFrame] = None
        self.metadata: Dict[str, Any] = {}
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
    def analyze_all_datasets(self) -> Dict[str, DatasetInfo]:
        """ëª¨ë“  CSV íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ"""
        csv_files = list(self.data_folder.glob("*.csv"))
        
        for csv_file in csv_files:
            try:
                # ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ ì‹œë„
                df = self._load_csv_with_encoding(csv_file)
                if df is not None:
                    info = self._analyze_dataset(df, csv_file.name)
                    self.datasets[csv_file.stem] = df
                    self.dataset_info[csv_file.stem] = info
                    self.logger.info(f"ë¶„ì„ ì™„ë£Œ: {csv_file.name}")
                    
            except Exception as e:
                self.logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {csv_file.name}: {e}")
                
        return self.dataset_info
    
    def _load_csv_with_encoding(self, filepath: Path) -> Optional[pd.DataFrame]:
        """ë‹¤ì–‘í•œ ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ ë¡œë“œ ì‹œë„"""
        encodings = ['utf-8', 'euc-kr', 'cp949', 'latin1']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(filepath, encoding=encoding)
                
                # êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ íŒŒì¼ì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
                if 'êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬' in filepath.name:
                    print(f"ğŸ“Š êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„° ë¡œë“œ: {filepath.name}")
                    print(f"   - ì›ë³¸ shape: {df.shape}")
                    print(f"   - ì²« ë²ˆì§¸ ì»¬ëŸ¼: {df.columns[0]}")
                    print(f"   - ë‘ ë²ˆì§¸ ì»¬ëŸ¼: {df.columns[1] if len(df.columns) > 1 else 'N/A'}")
                    
                    # 2017ë…„ê³¼ 2021ë…„ ë°ì´í„° í™•ì¸
                    if len(df.columns) > 1:
                        row_2017 = df[df.iloc[:, 0] == 2017]
                        row_2021 = df[df.iloc[:, 0] == 2021]
                        if not row_2017.empty:
                            print(f"   - 2017ë…„ ì´ë°°ì¶œëŸ‰: {row_2017.iloc[0, 1]} (ë°±ë§Œí†¤ COâ‚‚)")
                        if not row_2021.empty:
                            print(f"   - 2021ë…„ ì´ë°°ì¶œëŸ‰: {row_2021.iloc[0, 1]} (ë°±ë§Œí†¤ COâ‚‚)")
                    
                    # ë°ì´í„°ê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœì¸ì§€ í™•ì¸ (ì—°ë„ê°€ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ìˆëŠ” ê²½ìš°)
                    if df.iloc[:, 0].dtype in ['int64', 'float64'] or any(str(val).isdigit() and 1990 <= int(str(val)) <= 2030 for val in df.iloc[:, 0].dropna() if str(val).replace('.', '').isdigit()):
                        print("   - ë°ì´í„°ê°€ ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•íƒœ (ì—°ë„ê°€ ì²« ë²ˆì§¸ ì»¬ëŸ¼)")
                        # ì»¬ëŸ¼ëª… ì •ë¦¬
                        if len(df.columns) > 1:
                            df.columns = ['ì—°ë„', 'ì´ë°°ì¶œëŸ‰'] + list(df.columns[2:])
                        return df
                    
                    # ì „ì¹˜ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ìˆ˜í–‰
                    elif df.shape[0] < df.shape[1]:  # í–‰ë³´ë‹¤ ì—´ì´ ë” ë§ìœ¼ë©´ ì „ì¹˜
                        print("   - ì „ì¹˜(transpose) ìˆ˜í–‰")
                        df = df.set_index(df.columns[0]).T
                        df.index.name = 'ì—°ë„'
                        df = df.reset_index()
                        print(f"   - ì „ì¹˜ í›„ shape: {df.shape}")
                
                return df
                
            except (UnicodeDecodeError, pd.errors.EmptyDataError):
                continue
                
        return None
    
    def _analyze_dataset(self, df: pd.DataFrame, filename: str) -> DatasetInfo:
        """ê°œë³„ ë°ì´í„°ì…‹ ë¶„ì„"""
        # ì—°ë„ ì»¬ëŸ¼ ì°¾ê¸°
        year_pattern = r'(\d{4})'
        year_columns = []
        
        for col in df.columns:
            if re.search(year_pattern, str(col)):
                year_columns.append(col)
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ ì°¾ê¸°
        numeric_columns = []
        for col in df.columns:
            if df[col].dtype in ['int64', 'float64']:
                numeric_columns.append(col)
            else:
                # ë¬¸ìì—´ì´ì§€ë§Œ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œ ì»¬ëŸ¼ ì°¾ê¸°
                try:
                    pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')
                    if not df[col].isna().all():
                        numeric_columns.append(col)
                except:
                    pass
        
        # ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ ì°¾ê¸°
        categorical_columns = [col for col in df.columns if col not in numeric_columns]
        
        # ê²°ì¸¡ê°’ ê³„ì‚°
        missing_values = df.isnull().sum().to_dict()
        
        # ë°ì´í„° íƒ€ì… ì •ë³´
        data_types = {col: str(df[col].dtype) for col in df.columns}
        
        # íŒŒì¼ë³„ ì„¤ëª… ìƒì„±
        description = self._generate_description(filename, df)
        
        return DatasetInfo(
            filename=filename,
            shape=df.shape,
            columns=list(df.columns),
            data_types=data_types,
            has_year_columns=len(year_columns) > 0,
            year_columns=year_columns,
            numeric_columns=numeric_columns,
            categorical_columns=categorical_columns,
            missing_values=missing_values,
            description=description
        )
    
    def _generate_description(self, filename: str, df: pd.DataFrame) -> str:
        """íŒŒì¼ëª…ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª… ìƒì„±"""
        descriptions = {
            '3ì°¨_ì‚¬ì „í• ë‹¹': '3ì°¨ ê³„íšê¸°ê°„ ë°°ì¶œê¶Œ ì‚¬ì „í• ë‹¹ ë°ì´í„°',
            'ì¶”ê°€í• ë‹¹ëŸ‰': 'ë°°ì¶œê¶Œ ì¶”ê°€í• ë‹¹ëŸ‰ ë°ì´í„°',
            'ìƒì‡„ë°°ì¶œê¶Œ': 'ìƒì‡„ë°°ì¶œê¶Œ ë°œí–‰ëŸ‰ ë°ì´í„°',
            'CLM_ì˜¨ì‹¤ê°€ìŠ¤': 'ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ê´€ë ¨ ë°ì´í„°',
            'êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬': 'êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°°ì¶œëŸ‰ ë°ì´í„° (1990-2021)',
            'ê¸°ì—…_ê·œëª¨_ì§€ì—­ë³„': 'ê¸°ì—… ê·œëª¨ ë° ì§€ì—­ë³„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„°',
            'ë°°ì¶œê¶Œ_ê±°ë˜ë°ì´í„°': 'ë°°ì¶œê¶Œ ê±°ë˜ ê´€ë ¨ ë°ì´í„°',
            'ë°°ì¶œê¶Œì´ìˆ˜ëŸ‰': 'ë°°ì¶œê¶Œ ì´ìˆ˜ëŸ‰ ë°ì´í„°',
            'í•œêµ­ì—ë„ˆì§€ê³µë‹¨': 'ì‚°ì—…ë¶€ë¬¸ ì—ë„ˆì§€ì‚¬ìš© ë° ì˜¨ì‹¤ê°€ìŠ¤ë°°ì¶œëŸ‰ í†µê³„',
            'í™˜ê²½ë¶€': 'í™˜ê²½ë¶€ ì˜¨ì‹¤ê°€ìŠ¤ì¢…í•©ì •ë³´ì„¼í„° êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°°ì¶œëŸ‰'
        }
        
        for key, desc in descriptions.items():
            if key in filename:
                return desc
                
        return f"ì˜¨ì‹¤ê°€ìŠ¤ ê´€ë ¨ ë°ì´í„° ({filename})"
    
    def standardize_data(self) -> pd.DataFrame:
        """ëª¨ë“  ë°ì´í„°ë¥¼ í‘œì¤€í™”ëœ í˜•íƒœë¡œ í†µí•©"""
        unified_rows = []
        
        for dataset_name, df in self.datasets.items():
            info = self.dataset_info[dataset_name]
            
            # ì—°ë„ë³„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ì‹œê³„ì—´ í˜•íƒœë¡œ ë³€í™˜
            if info.has_year_columns:
                standardized = self._convert_to_timeseries(df, dataset_name, info)
                unified_rows.extend(standardized)
            else:
                # ì—°ë„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ë©”íƒ€ë°ì´í„°ë¡œ ì²˜ë¦¬
                self.metadata[dataset_name] = df.to_dict('records')
        
        # í†µí•© ë°ì´í„°í”„ë ˆì„ ìƒì„±
        if unified_rows:
            self.unified_data = pd.DataFrame(unified_rows)
            self.unified_data = self._clean_unified_data(self.unified_data)
            
        return self.unified_data
    
    def _convert_to_timeseries(self, df: pd.DataFrame, dataset_name: str, info: DatasetInfo) -> List[Dict]:
        """ë°ì´í„°ë¥¼ ì‹œê³„ì—´ í˜•íƒœë¡œ ë³€í™˜"""
        rows = []
        
        # ì—°ë„ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•„ì„œ ì‹œê³„ì—´ ë°ì´í„°ë¡œ ë³€í™˜
        year_columns = info.year_columns
        non_year_columns = [col for col in df.columns if col not in year_columns]
        
        for _, row in df.iterrows():
            # ê° ì—°ë„ë³„ë¡œ ë ˆì½”ë“œ ìƒì„±
            for year_col in year_columns:
                year = self._extract_year(year_col)
                if year:
                    record = {
                        'dataset': dataset_name,
                        'year': year,
                        'value': self._clean_numeric_value(row[year_col]),
                    }
                    
                    # ë¹„ì—°ë„ ì»¬ëŸ¼ë“¤ì„ ë©”íƒ€ë°ì´í„°ë¡œ ì¶”ê°€
                    for col in non_year_columns:
                        record[f'meta_{col}'] = row[col]
                    
                    rows.append(record)
        
        return rows
    
    def _extract_year(self, year_string: str) -> Optional[int]:
        """ë¬¸ìì—´ì—ì„œ ì—°ë„ ì¶”ì¶œ"""
        match = re.search(r'(\d{4})', str(year_string))
        if match:
            year = int(match.group(1))
            if 1990 <= year <= 2030:  # í•©ë¦¬ì ì¸ ì—°ë„ ë²”ìœ„
                return year
        return None
    
    def _clean_numeric_value(self, value: Any) -> Optional[float]:
        """ìˆ«ì ê°’ ì •ë¦¬"""
        if pd.isna(value):
            return None
            
        if isinstance(value, (int, float)):
            return float(value)
            
        # ë¬¸ìì—´ì¸ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
        try:
            # ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜
            cleaned = str(value).replace(',', '').replace(' ', '')
            return float(cleaned)
        except (ValueError, AttributeError):
            return None
    
    def _clean_unified_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """í†µí•© ë°ì´í„° ì •ë¦¬"""
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        df = df.dropna(subset=['value'])
        
        # ë°ì´í„° íƒ€ì… ìµœì í™”
        df['year'] = df['year'].astype(int)
        df['value'] = pd.to_numeric(df['value'], errors='coerce')
        
        # ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬ (IQR ë°©ë²•)
        Q1 = df['value'].quantile(0.25)
        Q3 = df['value'].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # ì´ìƒì¹˜ í”Œë˜ê·¸ ì¶”ê°€
        df['is_outlier'] = (df['value'] < lower_bound) | (df['value'] > upper_bound)
        
        # ì •ë ¬
        df = df.sort_values(['dataset', 'year']).reset_index(drop=True)
        
        return df
    
    def get_data_summary(self) -> Dict[str, Any]:
        """ë°ì´í„° ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        summary = {
            'total_datasets': len(self.datasets),
            'datasets_info': {},
            'unified_data_shape': self.unified_data.shape if self.unified_data is not None else None,
            'year_range': None,
            'total_records': 0
        }
        
        # ê° ë°ì´í„°ì…‹ ì •ë³´
        for name, info in self.dataset_info.items():
            summary['datasets_info'][name] = {
                'shape': info.shape,
                'columns_count': len(info.columns),
                'has_year_data': info.has_year_columns,
                'year_columns_count': len(info.year_columns),
                'description': info.description
            }
        
        # í†µí•© ë°ì´í„° ì •ë³´
        if self.unified_data is not None:
            summary['year_range'] = (
                self.unified_data['year'].min(),
                self.unified_data['year'].max()
            )
            summary['total_records'] = len(self.unified_data)
            summary['datasets_in_unified'] = self.unified_data['dataset'].nunique()
        
        return summary
    
    def get_dataset_by_name(self, name: str) -> Optional[pd.DataFrame]:
        """ì´ë¦„ìœ¼ë¡œ ë°ì´í„°ì…‹ ì¡°íšŒ"""
        return self.datasets.get(name)
    
    def get_unified_data(self) -> Optional[pd.DataFrame]:
        """í†µí•© ë°ì´í„° ë°˜í™˜"""
        return self.unified_data
    
    def filter_data(self, dataset: str = None, year_range: Tuple[int, int] = None, 
                   value_range: Tuple[float, float] = None) -> pd.DataFrame:
        """ì¡°ê±´ì— ë”°ë¥¸ ë°ì´í„° í•„í„°ë§"""
        if self.unified_data is None:
            return pd.DataFrame()
        
        filtered = self.unified_data.copy()
        
        if dataset:
            filtered = filtered[filtered['dataset'] == dataset]
        
        if year_range:
            start_year, end_year = year_range
            filtered = filtered[
                (filtered['year'] >= start_year) & 
                (filtered['year'] <= end_year)
            ]
        
        if value_range:
            min_val, max_val = value_range
            filtered = filtered[
                (filtered['value'] >= min_val) & 
                (filtered['value'] <= max_val)
            ]
        
        return filtered 