"""
í–¥ìƒëœ íƒ„ì†Œ RAG ì—ì´ì „íŠ¸
ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬, ì¿¼ë¦¬ ë¶„ì„, ì‹œê°í™” ì—”ì§„ì„ í†µí•©í•œ AI ì—ì´ì „íŠ¸
"""

import os
import pandas as pd
import numpy as np
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ ì‹œë„
try:
    load_dotenv()
    # .env íŒŒì¼ ë¡œë“œê°€ ì‹¤íŒ¨í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì§ì ‘ ì„¤ì •
    if not os.getenv('UPSTAGE_API_KEY'):
        # .env íŒŒì¼ì—ì„œ ì§ì ‘ ì½ê¸°
        env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
        if os.path.exists(env_path):
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#') and '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
except Exception as e:
    print(f"í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    # ì§ì ‘ ì„¤ì • (ìž„ì‹œ)
    os.environ['UPSTAGE_API_KEY'] = 'up_Tfh3KhtojqHp2MascmzOv3IG4lDu0'
from typing import List, Dict, Tuple, Optional, Any
from langchain_upstage import ChatUpstage
from langchain.schema import HumanMessage, SystemMessage
import warnings

# ìƒˆë¡œ êµ¬í˜„í•œ ëª¨ë“ˆë“¤ import
from .data_preprocessor import DataPreprocessor
from .query_analyzer import QueryAnalyzer, QueryIntent
from .visualization_engine import VisualizationEngine
from .metadata_manager import MetadataManager
from .code_executor import SafeCodeExecutor

warnings.filterwarnings('ignore')

# í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ì„¤ì •
if not os.getenv('UPSTAGE_API_KEY'):
    print("ðŸ”§ í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì„¤ì •í•©ë‹ˆë‹¤...")
    os.environ['UPSTAGE_API_KEY'] = 'up_Tfh3KhtojqHp2MascmzOv3IG4lDu0'

class EnhancedCarbonRAGAgent:
    """í–¥ìƒëœ íƒ„ì†Œ ë°ì´í„° RAG ì—ì´ì „íŠ¸"""
    
    _instance = None
    
    def __new__(cls):
        """ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„"""
        if cls._instance is None:
            cls._instance = super(EnhancedCarbonRAGAgent, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        """ì—ì´ì „íŠ¸ ì´ˆê¸°í™”"""
        if hasattr(self, '_initialized'):
            return
            
        # API í‚¤ í™•ì¸
        self.api_key = os.getenv('UPSTAGE_API_KEY')
        if not self.api_key:
            raise ValueError("UPSTAGE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # LLM ì´ˆê¸°í™”
        self.llm = ChatUpstage(
            api_key=self.api_key,
            model="solar-1-mini-chat"
        )
        
        # ë°ì´í„° í´ë” ê²½ë¡œ
        self.data_folder = "data"
        
        # ê³ ê¸‰ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.data_preprocessor = DataPreprocessor(self.data_folder)
        self.query_analyzer = QueryAnalyzer()
        self.visualization_engine = VisualizationEngine()
        self.metadata_manager = MetadataManager("agent/metadata.json")
        self.code_executor = SafeCodeExecutor()
        
        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        self._load_and_process_data()
        
        self._initialized = True
        print("âœ… í–¥ìƒëœ íƒ„ì†Œ RAG ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def _load_and_process_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ðŸ”„ ë°ì´í„° ë¶„ì„ ë° ì „ì²˜ë¦¬ ì¤‘...")
        
        # 1. ëª¨ë“  ë°ì´í„°ì…‹ ë¶„ì„
        self.dataset_info = self.data_preprocessor.analyze_all_datasets()
        
        # 2. ë°ì´í„° í‘œì¤€í™” ë° í†µí•©
        self.unified_data = self.data_preprocessor.standardize_data()
        
        # 3. ë©”íƒ€ë°ì´í„° ìƒì„±
        self.metadata_manager.analyze_and_create_metadata(self.data_preprocessor.datasets)
        
        # 4. ë°ì´í„° ìš”ì•½ ì •ë³´ ìƒì„±
        self.data_summary = self.data_preprocessor.get_data_summary()
        
        print(f"âœ… ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì´ {self.data_summary['total_datasets']}ê°œ ë°ì´í„°ì…‹ ë¡œë“œ")
        if self.unified_data is not None:
            print(f"   - í†µí•© ë°ì´í„°: {self.unified_data.shape[0]}í–‰ Ã— {self.unified_data.shape[1]}ì—´")
            print(f"   - ì—°ë„ ë²”ìœ„: {self.data_summary['year_range']}")
    
    def ask(self, question: str) -> Tuple[str, Optional[str]]:
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ë° ì‹œê°í™” ìƒì„±
        
        Args:
            question: ì‚¬ìš©ìž ì§ˆë¬¸
            
        Returns:
            (ë‹µë³€ í…ìŠ¤íŠ¸, ì‹œê°í™” ì´ë¯¸ì§€ base64)
        """
        try:
            print(f"ðŸŽ¯ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œìž‘: '{question}'")
            
            # 1. ì§ˆë¬¸ ì˜ë„ ë¶„ì„
            intent = self.query_analyzer.analyze_query(question)
            print(f"ðŸ” ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ: {intent.query_type.value} (ì‹ ë¢°ë„: {intent.confidence:.2f})")
            print(f"ðŸ“… ì¶”ì¶œëœ ì—°ë„: {intent.years}")
            print(f"ðŸ·ï¸ ì¶”ì¶œëœ ì—”í‹°í‹°: {intent.entities}")
            
            # 2. ì‹œê°í™” í•„ìš”ì„± íŒë‹¨
            needs_viz = self.query_analyzer.needs_visualization(question)
            print(f"ðŸ“Š ì‹œê°í™” í•„ìš”: {needs_viz}")
            
            # 3. ë°ì´í„° í•„í„°ë§ ë° ë¶„ì„
            analysis_result = self._perform_data_analysis(intent)
            print(f"ðŸ“ˆ ë¶„ì„ ê²°ê³¼ ì„±ê³µ: {analysis_result.get('success', False)}")
            if 'data' in analysis_result:
                print(f"ðŸ“Š ë¶„ì„ëœ ë°ì´í„° í¬ê¸°: {len(analysis_result['data']) if analysis_result['data'] is not None else 0}")
            
            # 4. ì‹œê°í™” ìƒì„± (í•„ìš”í•œ ê²½ìš°ë§Œ)
            visualization = None
            if needs_viz:
                print("ðŸŽ¨ ì‹œê°í™” ìƒì„± ì‹œìž‘...")
                visualization = self._create_visualization(intent, analysis_result)
                if visualization:
                    print("âœ… ì‹œê°í™” ìƒì„± ì™„ë£Œ")
                else:
                    print("âš ï¸ ì‹œê°í™” ìƒì„± ì‹¤íŒ¨")
            else:
                print("â„¹ï¸ í…ìŠ¤íŠ¸ ë‹µë³€ë§Œ ì œê³µ")
            
            # 5. ë‹µë³€ ìƒì„±
            answer = self._generate_answer(question, intent, analysis_result)
            
            return answer, visualization
            
        except Exception as e:
            error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            print(error_msg)
            import traceback
            traceback.print_exc()
            return error_msg, None
    
    def _perform_data_analysis(self, intent: QueryIntent) -> Dict[str, Any]:
        """ì§ˆë¬¸ ì˜ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„° ë¶„ì„ ìˆ˜í–‰"""
        if self.unified_data is None or self.unified_data.empty:
            return {"error": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        try:
            # ì½”ë“œ ìƒì„± ë° ì‹¤í–‰
            context = {"unified_data": self.unified_data}
            
            # ì§ˆë¬¸ ì˜ë„ì— ë”°ë¥¸ ë¶„ì„ ì½”ë“œ ìƒì„±
            analysis_code = self.code_executor.generate_analysis_code(
                intent, 
                list(self.unified_data.columns)
            )
            
            # ì½”ë“œ ì‹¤í–‰
            success, result, output = self.code_executor.execute_code(analysis_code, context)
            
            if success and result is not None:
                return {
                    "success": True,
                    "data": result,
                    "output": output,
                    "code": analysis_code
                }
            else:
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰
                return self._fallback_analysis(intent)
                
        except Exception as e:
            print(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
            return self._fallback_analysis(intent)
    
    def _fallback_analysis(self, intent: QueryIntent) -> Dict[str, Any]:
        """ê¸°ë³¸ ë¶„ì„ (ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ)"""
        try:
            # êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©
            inventory_dataset = None
            for dataset_name, df in self.data_preprocessor.datasets.items():
                if 'êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬' in dataset_name:
                    inventory_dataset = df
                    print(f"ðŸ“Š êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ì…‹ ì‚¬ìš©: {dataset_name}")
                    break
            
            if inventory_dataset is None or inventory_dataset.empty:
                return {"error": "êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # ì—°ë„ í•„í„°ë§
            if intent.years:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ì—°ë„ (ì´ë¯¸ data_preprocessorì—ì„œ í™•ì¸ë¨)
                year_mask = inventory_dataset.iloc[:, 0].isin(intent.years)
                filtered_data = inventory_dataset[year_mask].copy()
                print(f"ðŸ“… ì—°ë„ í•„í„°ë§: {intent.years} â†’ {len(filtered_data)}ê°œ ë ˆì½”ë“œ")
            else:
                filtered_data = inventory_dataset.copy()
            
            # ê²°ê³¼ ë°ì´í„° ì¤€ë¹„
            result_data = []
            
            # ì§ˆë¬¸ íƒ€ìž…ë³„ ë¶„ì„
            if intent.query_type.value == 'comparison' and intent.years:
                # ì—°ë„ë³„ ë¹„êµ: ê° ì—°ë„ì˜ ì´ë°°ì¶œëŸ‰ (ë‘ ë²ˆì§¸ ì»¬ëŸ¼)
                for year in intent.years:
                    year_row = inventory_dataset[inventory_dataset.iloc[:, 0] == year]
                    if not year_row.empty:
                        total_emission = year_row.iloc[0, 1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ ì´ë°°ì¶œëŸ‰
                        result_data.append({
                            'year': year,
                            'value': total_emission
                        })
                        print(f"ðŸ“ˆ {year}ë…„ ì´ë°°ì¶œëŸ‰: {total_emission:,.1f} (ë°±ë§Œí†¤ COâ‚‚)")
                
                result = pd.DataFrame(result_data)
                        
            elif intent.query_type.value == 'trend':
                # ì¶”ì„¸ ë¶„ì„: ëª¨ë“  ì—°ë„ì˜ ì´ë°°ì¶œëŸ‰
                for _, row in inventory_dataset.iterrows():
                    year = row.iloc[0]
                    total_emission = row.iloc[1]
                    if pd.notna(year) and pd.notna(total_emission):
                        result_data.append({
                            'year': int(year),
                            'value': float(total_emission)
                        })
                
                result = pd.DataFrame(result_data).sort_values('year')
            else:
                # ê¸°ë³¸: ìš”ì²­ëœ ì—°ë„ë“¤ì˜ ë°ì´í„°
                for _, row in filtered_data.iterrows():
                    year = row.iloc[0]
                    total_emission = row.iloc[1]
                    if pd.notna(year) and pd.notna(total_emission):
                        result_data.append({
                            'year': int(year),
                            'value': float(total_emission)
                        })
                
                result = pd.DataFrame(result_data)
            
            if result.empty:
                return {"error": "ìš”ì²­í•œ ì—°ë„ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            return {
                "success": True,
                "data": result,
                "output": f"êµ­ê°€ ì˜¨ì‹¤ê°€ìŠ¤ ì¸ë²¤í† ë¦¬ ë¶„ì„ ì™„ë£Œ - ì´ë°°ì¶œëŸ‰ ê¸°ì¤€ (ë°±ë§Œí†¤ COâ‚‚)"
            }
            
        except Exception as e:
            print(f"ê¸°ë³¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {"error": f"ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}"}
    
    def _create_visualization(self, intent: QueryIntent, analysis_result: Dict[str, Any]) -> Optional[str]:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œê°í™” ìƒì„±"""
        if not analysis_result.get("success") or analysis_result.get("data") is None:
            return None
        
        try:
            data = analysis_result["data"]
            
            # ì‹œê°í™” ë§¤ê°œë³€ìˆ˜ ìƒì„±
            viz_params = self.query_analyzer.suggest_visualization_params(intent)
            
            # ì°¨íŠ¸ ì œëª© ìƒì„±
            title = self._generate_chart_title(intent)
            
            # ì‹œê°í™” ìƒì„±
            visualization = self.visualization_engine.create_visualization(
                data=data,
                chart_type=intent.chart_type.value,
                title=title,
                params=viz_params
            )
            
            return visualization
            
        except Exception as e:
            print(f"ì‹œê°í™” ìƒì„± ì˜¤ë¥˜: {e}")
            return None
    
    def _generate_chart_title(self, intent: QueryIntent) -> str:
        """ì°¨íŠ¸ ì œëª© ìƒì„±"""
        if intent.query_type.value == 'comparison' and intent.years:
            if len(intent.years) == 2:
                return f"{intent.years[0]}ë…„ê³¼ {intent.years[1]}ë…„ ë°°ì¶œëŸ‰ ë¹„êµ"
            else:
                return f"{min(intent.years)}-{max(intent.years)}ë…„ ë°°ì¶œëŸ‰ ë¹„êµ"
        elif intent.query_type.value == 'trend':
            return "ì—°ë„ë³„ ë°°ì¶œëŸ‰ ë³€í™” ì¶”ì´"
        elif intent.query_type.value == 'ranking':
            return "ë¶„ì•¼ë³„ ë°°ì¶œëŸ‰ ìˆœìœ„"
        else:
            return "ë°°ì¶œëŸ‰ ë¶„ì„ ê²°ê³¼"
    
    def _generate_answer(self, question: str, intent: QueryIntent, analysis_result: Dict[str, Any]) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìžì—°ì–´ ë‹µë³€ ìƒì„±"""
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = f"""
ë‹¹ì‹ ì€ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ìž…ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ì§ˆë¬¸ íƒ€ìž…: {intent.query_type.value}
ì‹ ë¢°ë„: {intent.confidence:.2f}
ì¶”ì¶œëœ ì—°ë„: {intent.years}
ê´€ë ¨ ë¶„ì•¼: {intent.entities}
ë©”íŠ¸ë¦­: {intent.metrics}

ë¶„ì„ ê²°ê³¼:
{analysis_result.get('output', 'ë¶„ì„ ê²°ê³¼ ì—†ìŒ')}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì— ë§žì¶° ë‹µë³€í•´ì£¼ì„¸ìš”:

1. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€
2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ í¬í•¨
3. ê°„ë‹¨í•œ í•´ì„ ë° ì¸ì‚¬ì´íŠ¸ ì œê³µ
4. í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê²Œ ì„¤ëª…
5. 3-5ë¬¸ìž¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìž‘ì„±

ë°ì´í„° ì¶œì²˜: í™˜ê²½ë¶€, í•œêµ­ê±°ëž˜ì†Œ, í•œêµ­ì—ë„ˆì§€ê³µë‹¨ ë“± ê³µê³µê¸°ê´€
"""
            
            # LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=question)
            ]
            
            response = self.llm.invoke(messages)
            return response.content
            
        except Exception as e:
            # LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë‹µë³€
            return self._generate_fallback_answer(question, analysis_result)
    
    def _generate_fallback_answer(self, question: str, analysis_result: Dict[str, Any]) -> str:
        """ê¸°ë³¸ ë‹µë³€ ìƒì„± (LLM ì‹¤íŒ¨ ì‹œ)"""
        if analysis_result.get("error"):
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {analysis_result['error']}"
        
        if analysis_result.get("data") is not None:
            data = analysis_result["data"]
            
            if isinstance(data, pd.DataFrame) and not data.empty:
                # ê¸°ë³¸ì ì¸ í†µê³„ ì •ë³´ ì œê³µ
                if 'value' in data.columns:
                    total = data['value'].sum()
                    avg = data['value'].mean()
                    return f"ë¶„ì„ ê²°ê³¼, ì´ ë°°ì¶œëŸ‰ì€ {total:,.0f}ì´ë©°, í‰ê· ì€ {avg:,.0f}ìž…ë‹ˆë‹¤. ìžì„¸í•œ ë‚´ìš©ì€ ìœ„ì˜ ê·¸ëž˜í”„ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”."
                else:
                    return f"ë°ì´í„° ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ {len(data)}ê°œì˜ ë ˆì½”ë“œê°€ ìžˆìŠµë‹ˆë‹¤."
            else:
                return "ë°ì´í„°ê°€ ë¹„ì–´ìžˆê±°ë‚˜ ë¶„ì„í•  ìˆ˜ ì—†ëŠ” í˜•íƒœìž…ë‹ˆë‹¤."
        
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ì„ ì™„ë£Œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    
    def get_available_data_info(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ì •ë³´ ë°˜í™˜"""
        info_parts = ["ðŸ“Š **ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°:**\n"]
        
        for name, info in self.dataset_info.items():
            info_parts.append(f"**{name}**")
            info_parts.append(f"- {info.description}")
            info_parts.append(f"- í¬ê¸°: {info.shape[0]}í–‰ Ã— {info.shape[1]}ì—´")
            if info.has_year_columns:
                years = [str(col) for col in info.year_columns[:5]]  # ì²˜ìŒ 5ê°œë§Œ
                info_parts.append(f"- ì—°ë„: {', '.join(years)}...")
            info_parts.append("")
        
        # í†µí•© ë°ì´í„° ì •ë³´
        if self.unified_data is not None:
            info_parts.append("**ðŸ“ˆ í†µí•© ë¶„ì„ ë°ì´í„°:**")
            info_parts.append(f"- ì „ì²´ ë ˆì½”ë“œ: {len(self.unified_data):,}ê°œ")
            info_parts.append(f"- ì—°ë„ ë²”ìœ„: {self.data_summary['year_range']}")
            info_parts.append(f"- ë°ì´í„°ì…‹ ìˆ˜: {self.data_summary['datasets_in_unified']}ê°œ")
        
        return "\n".join(info_parts)
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            "datasets_loaded": len(self.dataset_info),
            "unified_data_size": len(self.unified_data) if self.unified_data is not None else 0,
            "metadata_available": len(self.metadata_manager.metadata),
            "execution_history": self.code_executor.get_execution_summary(),
            "data_summary": self.data_summary
        }
    
    def debug_query(self, question: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ ë””ë²„ê¹… ì •ë³´ ì œê³µ"""
        intent = self.query_analyzer.analyze_query(question)
        
        return {
            "question": question,
            "intent": {
                "query_type": intent.query_type.value,
                "chart_type": intent.chart_type.value,
                "years": intent.years,
                "entities": intent.entities,
                "metrics": intent.metrics,
                "confidence": intent.confidence
            },
            "suggested_params": self.query_analyzer.suggest_visualization_params(intent),
            "available_data": list(self.dataset_info.keys())
        } 